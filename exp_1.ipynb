{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itsyashkhurana/Big-Data-Analystics/blob/main/exp_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import kagglehub\n",
        "\n",
        "# Download the dataset\n",
        "path = kagglehub.dataset_download(\"borismarjanovic/price-volume-data-for-all-us-stocks-etfs\")\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "# Specify the dataset path\n",
        "data_directory = os.path.join(path, \"Data\", \"Stocks\")\n",
        "\n",
        "\n",
        "# List all .txt files in the directory\n",
        "txt_files = [file for file in os.listdir(data_directory) if file.endswith('.txt')]\n",
        "print(f\"Number of .txt files found: {len(txt_files)}\")\n",
        "print(\"Sample files:\", txt_files[:5])\n",
        "\n",
        "# Initialize an empty DataFrame for combined data\n",
        "combined_data = pd.DataFrame()\n",
        "\n",
        "# Loop through and read .txt files\n",
        "for file in txt_files[:100]:  # Adjust range as needed\n",
        "    try:\n",
        "        file_path = os.path.join(data_directory, file)\n",
        "        temp_data = pd.read_csv(file_path, delimiter=',')  # Update delimiter if necessary\n",
        "        combined_data = pd.concat([combined_data, temp_data], ignore_index=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading {file}: {e}\")\n",
        "\n",
        "# === Volume (Number of rows and columns) ===\n",
        "print(\"=== Volume ===\")\n",
        "print(\"Combined Data Shape:\", combined_data.shape)\n",
        "print(f\"Total size of the dataset: {combined_data.memory_usage(deep=True).sum() / (1024**2):.2f} MB\")  # Memory size in MB\n",
        "\n",
        "# === Variety (Data types and unique values) ===\n",
        "print(\"=== Variety ===\")\n",
        "print(\"Data Types:\\n\", combined_data.dtypes)\n",
        "\n",
        "# List unique values for categorical features (if applicable)\n",
        "categorical_columns = combined_data.select_dtypes(include='object').columns\n",
        "if not categorical_columns.empty:\n",
        "    for col in categorical_columns:\n",
        "        print(f\"Unique values in '{col}': {combined_data[col].nunique()}\")\n",
        "\n",
        "# Clean up 'Date' column and analyze time velocity\n",
        "combined_data['Date'] = pd.to_datetime(combined_data['Date'], errors='coerce')  # Handle errors in date parsing\n",
        "combined_data = combined_data.sort_values('Date')\n",
        "\n",
        "# === Velocity (Average time between entries) ===\n",
        "velocity = combined_data['Date'].diff().mean()\n",
        "print(\"=== Velocity (Average Time Between Entries) ===\")\n",
        "print(\"Average Time Between Entries (Velocity):\", velocity)\n",
        "print(f\"Time range of the dataset: From {combined_data['Date'].min()} to {combined_data['Date'].max()}\")\n",
        "\n",
        "# === Veracity (Missing values) ===\n",
        "print(\"=== Veracity (Missing Values) ===\")\n",
        "print(\"Missing Values:\\n\", combined_data.isnull().sum())\n",
        "\n",
        "# Check for outliers in numerical columns (e.g., using IQR method)\n",
        "numerical_columns = combined_data.select_dtypes(include=['float64', 'int64']).columns\n",
        "for col in numerical_columns:\n",
        "    Q1 = combined_data[col].quantile(0.25)\n",
        "    Q3 = combined_data[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    outliers = ((combined_data[col] < (Q1 - 1.5 * IQR)) | (combined_data[col] > (Q3 + 1.5 * IQR)))\n",
        "    print(f\"Number of outliers in '{col}': {outliers.sum()}\")\n",
        "\n",
        "# === Value (Descriptive statistics and correlations) ===\n",
        "print(\"=== Value (Descriptive Statistics) ===\")\n",
        "print(\"Descriptive Statistics:\\n\", combined_data.describe())\n",
        "\n",
        "# Correlation matrix to understand relationships between numerical features\n",
        "correlation_matrix = combined_data[numerical_columns].corr()\n",
        "print(\"Correlation Matrix:\\n\", correlation_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-8eDfEkai41",
        "outputId": "f352a751-a43b-48c7-a4bf-f5ad36b1d880"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/borismarjanovic/price-volume-data-for-all-us-stocks-etfs/versions/3\n",
            "Number of .txt files found: 7195\n",
            "Sample files: ['tile.us.txt', 'ggn_b.us.txt', 'cwco.us.txt', 'vrna.us.txt', 'cwai.us.txt']\n",
            "Error reading bxg.us.txt: No columns to parse from file\n",
            "=== Volume ===\n",
            "Combined Data Shape: (199348, 7)\n",
            "Total size of the dataset: 21.86 MB\n",
            "=== Variety ===\n",
            "Data Types:\n",
            " Date        object\n",
            "Open       float64\n",
            "High       float64\n",
            "Low        float64\n",
            "Close      float64\n",
            "Volume       int64\n",
            "OpenInt      int64\n",
            "dtype: object\n",
            "Unique values in 'Date': 8366\n",
            "=== Velocity (Average Time Between Entries) ===\n",
            "Average Time Between Entries (Velocity): 0 days 01:27:31.690770365\n",
            "Time range of the dataset: From 1984-09-07 00:00:00 to 2017-11-10 00:00:00\n",
            "=== Veracity (Missing Values) ===\n",
            "Missing Values:\n",
            " Date       0\n",
            "Open       0\n",
            "High       0\n",
            "Low        0\n",
            "Close      0\n",
            "Volume     0\n",
            "OpenInt    0\n",
            "dtype: int64\n",
            "Number of outliers in 'Open': 14162\n",
            "Number of outliers in 'High': 14146\n",
            "Number of outliers in 'Low': 14197\n",
            "Number of outliers in 'Close': 14154\n",
            "Number of outliers in 'Volume': 30919\n",
            "Number of outliers in 'OpenInt': 0\n",
            "=== Value (Descriptive Statistics) ===\n",
            "Descriptive Statistics:\n",
            "                                 Date           Open           High  \\\n",
            "count                         199348  199348.000000  199348.000000   \n",
            "mean   2010-10-24 10:45:18.943756544      24.639469      24.955459   \n",
            "min              1984-09-07 00:00:00       0.080000       0.080000   \n",
            "25%              2007-12-07 00:00:00       8.580600       8.715600   \n",
            "50%              2012-01-05 00:00:00      15.923500      16.170000   \n",
            "75%              2015-05-21 00:00:00      28.737250      29.132250   \n",
            "max              2017-11-10 00:00:00  199999.990000  199999.990000   \n",
            "std                              NaN     448.713681     448.735701   \n",
            "\n",
            "                 Low          Close        Volume   OpenInt  \n",
            "count  199348.000000  199348.000000  1.993480e+05  199348.0  \n",
            "mean       23.307355      23.632711  1.692962e+06       0.0  \n",
            "min         0.033600       0.033600  0.000000e+00       0.0  \n",
            "25%         8.430650       8.580000  3.372675e+04       0.0  \n",
            "50%        15.677500      15.934500  1.599105e+05       0.0  \n",
            "75%        28.310000      28.730000  7.864855e+05       0.0  \n",
            "max       500.550000     507.900000  6.351870e+08       0.0  \n",
            "std        26.748973      27.140133  5.597737e+06       0.0  \n",
            "Correlation Matrix:\n",
            "              Open      High       Low     Close    Volume  OpenInt\n",
            "Open     1.000000  0.999998  0.059796  0.059814 -0.005064      NaN\n",
            "High     0.999998  1.000000  0.060613  0.060651 -0.005051      NaN\n",
            "Low      0.059796  0.060613  1.000000  0.999661 -0.074071      NaN\n",
            "Close    0.059814  0.060651  0.999661  1.000000 -0.072825      NaN\n",
            "Volume  -0.005064 -0.005051 -0.074071 -0.072825  1.000000      NaN\n",
            "OpenInt       NaN       NaN       NaN       NaN       NaN      NaN\n"
          ]
        }
      ]
    }
  ]
}